{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9f3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, unix_timestamp, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddedc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/02 15:09:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30cd9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c51f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", True).parquet(\"yellow_tripdata_2024-10.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b55823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repartitioned = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87ca7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_repartitioned.write.mode(\"overwrite\").parquet(\"homework_W5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e6df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25M\thomework_W5/part-00000-d508ccc3-a4b7-47af-bf6d-022e2399a3d7-c000.snappy.parquet\r\n",
      "25M\thomework_W5/part-00001-d508ccc3-a4b7-47af-bf6d-022e2399a3d7-c000.snappy.parquet\r\n",
      "25M\thomework_W5/part-00002-d508ccc3-a4b7-47af-bf6d-022e2399a3d7-c000.snappy.parquet\r\n",
      "25M\thomework_W5/part-00003-d508ccc3-a4b7-47af-bf6d-022e2399a3d7-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh homework_W5/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a5daa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of taxi trips on October 15, 2024: 128893\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df.withColumn(\"pickup_date\", to_date(col(\"tpep_pickup_datetime\"))) \\\n",
    "                .filter(col(\"pickup_date\") == \"2024-10-15\")\n",
    "\n",
    "# Count the number of trips\n",
    "trip_count = df_filtered.count()\n",
    "print(f\"Number of taxi trips on October 15, 2024: {trip_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f226ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[VendorID: int, tpep_pickup_datetime: timestamp, tpep_dropoff_datetime: timestamp, passenger_count: bigint, trip_distance: double, RatecodeID: bigint, store_and_fwd_flag: string, PULocationID: int, DOLocationID: int, payment_type: bigint, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, Airport_fee: double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc4143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2024, 10, 1, 0, 30, 44), tpep_dropoff_datetime=datetime.datetime(2024, 10, 1, 0, 48, 26), passenger_count=1, trip_distance=3.0, RatecodeID=1, store_and_fwd_flag='N', PULocationID=162, DOLocationID=246, payment_type=1, fare_amount=18.4, extra=1.0, mta_tax=0.5, tip_amount=1.5, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=24.9, congestion_surcharge=2.5, Airport_fee=0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83cd8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_duration = df.withColumn(\n",
    "    \"trip_duration_hours\", \n",
    "    (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9f601e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durata del viaggio più lungo: 162.62 ore\n"
     ]
    }
   ],
   "source": [
    "longest_trip = df_with_duration.select(max(\"trip_duration_hours\")).collect()[0][0]\n",
    "\n",
    "print(f\"Durata del viaggio più lungo: {longest_trip:.2f} ore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c06a12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the taxi zone lookup CSV\n",
    "zone_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"taxi_zone_lookup.csv\")\n",
    "\n",
    "# Create a temporary view\n",
    "zone_df.createOrReplaceTempView(\"zone_lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "900b992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Yellow Taxi October 2024 dataset (update path accordingly)\n",
    "taxi_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).parquet(\"yellow_tripdata_2024-10.parquet\")\n",
    "\n",
    "# Create a temporary view\n",
    "taxi_df.createOrReplaceTempView(\"yellow_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d2e34b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         pickup_zone|trip_count|\n",
      "+--------------------+----------+\n",
      "|Governor's Island...|         1|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "least_frequent_zone = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        z.Zone AS pickup_zone,\n",
    "        COUNT(t.PULocationID) AS trip_count\n",
    "    FROM yellow_taxi t\n",
    "    JOIN zone_lookup z \n",
    "    ON t.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone\n",
    "    ORDER BY trip_count ASC\n",
    "    LIMIT 1\n",
    "\"\"\")\n",
    "\n",
    "least_frequent_zone.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6678ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
